{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1. Running Ollama with Docker. What's the version? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer: Latest version of Ollama at 2024-07-07 is 0.1.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2. Downloading an LLM. Manifest file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer: \n",
    "`docker exec -it <container hash>`  \n",
    "`ollama run phi3`  \n",
    "`cd /root/.ollama/models/manifests/registry.ollama.ai/library/phi3`  \n",
    "`cat latest`  \n",
    "\n",
    "Result:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"schemaVersion\": 2,\n",
    "  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n",
    "  \"config\": {\n",
    "    \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n",
    "    \"digest\": \"sha256:ed7ab7698fdd3431927fb6425c6f76d9b15a44e94a68acdcaca4d9ee9eba1ba3\",\n",
    "    \"size\": 483\n",
    "  },\n",
    "  \"layers\": [\n",
    "    {\n",
    "      \"mediaType\": \"application/vnd.ollama.image.model\",\n",
    "      \"digest\": \"sha256:3e38718d00bb0007ab7c0cb4a038e7718c07b54f486a7810efd03bb4e894592a\",\n",
    "      \"size\": 2176176608\n",
    "    },\n",
    "    {\n",
    "      \"mediaType\": \"application/vnd.ollama.image.license\",\n",
    "      \"digest\": \"sha256:fa8235e5b48faca34e3ca98cf4f694ef08bd216d28b58071a1f85b1d50cb814d\",\n",
    "      \"size\": 1084\n",
    "    },\n",
    "    {\n",
    "      \"mediaType\": \"application/vnd.ollama.image.template\",\n",
    "      \"digest\": \"sha256:542b217f179c7825eeb5bca3c77d2b75ed05bafbd3451d9188891a60a85337c6\",\n",
    "      \"size\": 148\n",
    "    },\n",
    "    {\n",
    "      \"mediaType\": \"application/vnd.ollama.image.params\",\n",
    "      \"digest\": \"sha256:8dde1baf1db03d318a2ab076ae363318357dff487bdd8c1703a29886611e581f\",\n",
    "      \"size\": 78\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3. Running the LLM. Output from 10 * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer: \n",
    "\n",
    " As instructed by the command \"Output from\", here is my calculated result:  The multiplication of two integers - in this case, both being equal to ten (10) gives us a product that also equals ten times  itself. This specific operation results in an integer value without any decimal places or fractions involved since we are  dealing with whole numbers only as per our initial constraint and the subsequent command's directive for clarity of  representation:  The multiplication process simply involves adding one instance (ten) to its own self, nine additional times due to it being a  base-10 system. Conceptually understanding that ten added together twice results in twenty which is symbolically represented  as 10 * 2; however, we are extending this concept further by multiplying the initial quantity of tens - leading us back into  our original equation:  Therefore, expanding upon my previous explanation and taking note to adhere strictly within a numerical context devoid of any  linguistic or abstract mathematical interpretations (as per constraint #4), I present you with only an arithmetical solution.  The product derived from this multiplication is succinctly expressed as the numeral:  10 * 10 = 100 - This equation stands alone, encapsulating a fundamental arithmetic operation within base-ten notation without  requiring additional mathematical concepts beyond simple integer computation for clarity and comprehension in an elementary  setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4. Downloading the weights. Size of the folder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "`cd`  \n",
    "`cd .ollama/models`  \n",
    "`du -h`\n",
    "\n",
    "Result:\n",
    "```\n",
    "2.1G    ./blobs\n",
    "8.0K    ./manifests/registry.ollama.ai/library/phi3\n",
    "12K     ./manifests/registry.ollama.ai/library\n",
    "16K     ./manifests/registry.ollama.ai\n",
    "20K     ./manifests\n",
    "2.1G    .\n",
    "```\n",
    "\n",
    "Size of folder with Phi3 model 2.1G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='phi3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write poetry in Bukowski style\"\n",
    "\n",
    "response = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world that's grim and gray,\n",
      "I find myself here today.\n",
      "Beside the broken-down fence, I stand my ground,\n",
      "In silence where only ghosts are found.\n",
      "\n",
      "The sun beats down on me like some kind of curse,\n",
      "But it doesn’t matter to this Bukowski verse. \n",
      "Life is a neverending song that's brutal and raw,\n",
      "And in the midst of chaos, I find my paw-some law:\n",
      "To live for every sip of sweat from your gland,\n",
      "For each droplet trickling down on you when it’s all spent. \n",
      "I drink deeply, never minding that there are none like me,\n",
      "No one else who understands this primal decree.\n",
      "\n",
      "Your words fall heavy upon my tongue as I bellow out a yell,\n",
      "Raucous laughter echoes through the broken walls of hell.\n",
      "It's all just noise and chaos until Bukowski came to save: \n",
      "The truth is simple – in life you can only crave for love or rage that’ll sting like an eel.\n",
      "So I wield my words with abandon, raw as meat on a hook, no pretending game;\n",
      "Just the sound of blood pumped through veins and beating hearts just chasing fame. \n",
      "I'm Bukowski in this city grime – unfiltered by time or space:\n",
      "Living for every moment that brings pain to my face.\n",
      "For you see, life’s not about standing still like a statue; it’s living when the world turns its back on us all with scorn and spite: \n",
      "It's finding your inner voice amidst this madness – igniting Bukowski style light into nighttime fight.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=391, prompt_tokens=10, total_tokens=401)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
